{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gymnasium's Pusher task : SAC Torchrl torial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchrl in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: torch>=2.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from torchrl) (2.2.0)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from torchrl) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from torchrl) (23.2)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torchrl) (3.0.0)\n",
      "Requirement already satisfied: tensordict>=0.3.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torchrl) (0.3.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=2.1.0->torchrl) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->torchrl) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->torchrl) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch>=2.1.0->torchrl) (1.3.0)\n",
      "Requirement already satisfied: gymnasium[mujoco] in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/codespace/.local/lib/python3.10/site-packages (from gymnasium[mujoco]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from gymnasium[mujoco]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from gymnasium[mujoco]) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from gymnasium[mujoco]) (0.0.4)\n",
      "Requirement already satisfied: mujoco>=2.3.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from gymnasium[mujoco]) (3.1.2)\n",
      "Requirement already satisfied: imageio>=2.14.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from gymnasium[mujoco]) (2.34.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/codespace/.local/lib/python3.10/site-packages (from imageio>=2.14.1->gymnasium[mujoco]) (10.2.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/python/3.10.13/lib/python3.10/site-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (2.1.0)\n",
      "Requirement already satisfied: etils[epath] in /usr/local/python/3.10.13/lib/python3.10/site-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (1.7.0)\n",
      "Requirement already satisfied: glfw in /usr/local/python/3.10.13/lib/python3.10/site-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (2.6.5)\n",
      "Requirement already satisfied: pyopengl in /usr/local/python/3.10.13/lib/python3.10/site-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (3.1.7)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.10/site-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (2024.2.0)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/python/3.10.13/lib/python3.10/site-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (6.1.1)\n",
      "Requirement already satisfied: zipp in /usr/local/python/3.10.13/lib/python3.10/site-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (3.17.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchrl\n",
    "!pip3 install gymnasium[mujoco]\n",
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "from tensordict.nn import TensorDictModule, InteractionType\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "\n",
    "# Tensordict modules\n",
    "from torch import multiprocessing\n",
    "\n",
    "# Data collection\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "\n",
    "# Env\n",
    "from torchrl.envs.libs.gym import GymEnv\n",
    "import gymnasium, gym\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "\n",
    "# Model and policy\n",
    "from torchrl.modules import MLP, ProbabilisticActor, TanhNormal, ValueOperator\n",
    "# Loss\n",
    "from torchrl.objectives import SoftUpdate\n",
    "from torchrl.objectives.sac import SACLoss\n",
    "\n",
    "# Utils\n",
    "torch.manual_seed(0)\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "2024-02-25 17:25:45,979 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1708881945.980131\n"
     ]
    }
   ],
   "source": [
    "# Devices\n",
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "gym_device = device  # The device where the simulator is run (VMAS can run on GPU)\n",
    "\n",
    "# Sampling\n",
    "frames_per_batch = 6_000  # Number of team frames collected per training iteration\n",
    "n_iters = 10  # Number of sampling and training iterations\n",
    "total_frames = frames_per_batch * n_iters\n",
    "\n",
    "# Training\n",
    "num_epochs = 20  # Number of optimization steps per training iteration\n",
    "minibatch_size = 400  # Size of the mini-batches in each optimization step\n",
    "lr = 3e-5  # Learning rate\n",
    "\n",
    "# SAC\n",
    "value_loss='l2' # 'smooth_l1' 'l2'; loss function to be used with the value function loss\n",
    "gamma = 0.9  # discount factor\n",
    "polyak = 0.995 # lambda for generalised advantage estimation\n",
    "\n",
    "# Model\n",
    "layers_config = [256, 64, 32]  # Number of units per layer in the network\n",
    "\n",
    "# GYM\n",
    "scenario_name = \"Pusher-v4\"\n",
    "max_steps = 200\n",
    "\n",
    "env = GymEnv(\n",
    "    env_name=scenario_name,\n",
    "    device=gym_device,\n",
    ")\n",
    "\n",
    "check_env_specs(env)\n",
    "\n",
    "time = time.time()\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space Box(-inf, inf, (23,), float64)\n",
      "action_space Box(-2.0, 2.0, (7,), float32)\n",
      "observation size 23\n"
     ]
    }
   ],
   "source": [
    "print(\"observation_space\", env.observation_space)\n",
    "print(\"action_space\", env.action_space)\n",
    "print(\"observation size\", env.observation_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_policy_module(env, layers_config, device):\n",
    "    policy_net = MLP(\n",
    "        in_features=env.observation_space.shape[0],\n",
    "        out_features=env.action_space.shape[0] * 2,  # 2 outputs per action: loc and scale\n",
    "        device=device,\n",
    "        depth=len(layers_config),\n",
    "        num_cells=layers_config,\n",
    "        activation_class=torch.nn.LeakyReLU,\n",
    "    )\n",
    "\n",
    "    seq_policy_net = torch.nn.Sequential(\n",
    "        policy_net,\n",
    "        NormalParamExtractor(),  # this will just separate the last dimension into two outputs: a loc and a non-negative scale\n",
    "    )\n",
    "\n",
    "    policy_module = TensorDictModule(\n",
    "        seq_policy_net,\n",
    "        in_keys=[\"observation\"],\n",
    "        out_keys=[\"loc\", \"scale\"],\n",
    "    )\n",
    "\n",
    "    policy = ProbabilisticActor(\n",
    "        module=policy_module,\n",
    "        in_keys=[\"loc\", \"scale\"],\n",
    "        out_keys=[\"action\"],\n",
    "        spec=env.action_spec,\n",
    "        distribution_class=TanhNormal,\n",
    "        distribution_kwargs={\n",
    "            \"min\": env.action_spec.space.minimum,\n",
    "            \"max\": env.action_spec.space.maximum,\n",
    "            \"tanh_loc\": False,\n",
    "        },\n",
    "        default_interaction_type=InteractionType.RANDOM,\n",
    "        return_log_prob=False,\n",
    "    )\n",
    "\n",
    "    return policy\n",
    "\n",
    "def make_Qval_module(env, layers_config, device):\n",
    "    Qval_net = MLP(\n",
    "        in_features=env.observation_space.shape[0] + env.action_space.shape[0],\n",
    "        out_features=1,  # 2 outputs per action: loc and scale\n",
    "        device=device,\n",
    "        depth=len(layers_config),\n",
    "        num_cells=layers_config,\n",
    "        activation_class=torch.nn.LeakyReLU,\n",
    "    )\n",
    "\n",
    "    Qval = ValueOperator(\n",
    "        module=Qval_net,\n",
    "        in_keys=[\"observation\", \"action\"],\n",
    "    )\n",
    "\n",
    "    return Qval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_collector(env, policy, device, storing_device, frames_per_batch, init_random_frames, total_frames, max_steps_per_traj=1000):\n",
    "    return SyncDataCollector(\n",
    "        env,\n",
    "        policy,\n",
    "        device=device,\n",
    "        storing_device=storing_device,\n",
    "        frames_per_batch=frames_per_batch,\n",
    "        init_random_frames=init_random_frames,\n",
    "        total_frames=total_frames,\n",
    "        max_frames_per_traj=max_steps_per_traj,\n",
    "        \n",
    "    )\n",
    "\n",
    "def make_replay_buffer(frames_per_batch, minibatch_size, device):\n",
    "    return ReplayBuffer(\n",
    "        storage=LazyTensorStorage(\n",
    "            frames_per_batch, device=device\n",
    "        ),  # We store the frames_per_batch collected at each iteration\n",
    "        sampler=SamplerWithoutReplacement(),\n",
    "        batch_size=minibatch_size,  # We will sample minibatches of this size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loss_module(env, policy, Qval, value_loss, gamma, polyak, lr):\n",
    "    loss_module = SACLoss(\n",
    "        actor_network=policy,\n",
    "        qvalue_network=Qval,\n",
    "        loss_function=value_loss,\n",
    "        action_spec=env.action_spec,\n",
    "    )\n",
    "    loss_module.make_value_estimator(gamma=gamma)\n",
    "    target_net_updater = SoftUpdate(loss_module,\n",
    "                                    eps=polyak)\n",
    "    optim = torch.optim.Adam(loss_module.parameters(),\n",
    "                             lr=lr)\n",
    "    \n",
    "    return loss_module, target_net_updater, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(\n",
    "    env,\n",
    "    loss_module,\n",
    "    target_net_updater,\n",
    "    optim,\n",
    "    collector,\n",
    "    replay_buffer,\n",
    "    n_iters,\n",
    "    num_epochs,\n",
    "    frames_per_batch,\n",
    "    minibatch_size):\n",
    "\n",
    "    rewards = []\n",
    "    rewards_eval = []\n",
    "\n",
    "    # Main loop\n",
    "    pbar = tqdm(total=n_iters, desc=\"episode_reward_mean = 0\")\n",
    "\n",
    "    q_loss = None\n",
    "\n",
    "    episode_reward_mean_list = []\n",
    "\n",
    "    for tensordict_data in collector:\n",
    "        # We need to expand the done and terminated to match the reward shape (this is expected by the value estimator)\n",
    "        data_view = tensordict_data.reshape(-1)  # Flatten the batch size to shuffle data\n",
    "        replay_buffer.extend(data_view)\n",
    "\n",
    "        for _ in range(num_epochs):\n",
    "            for _ in range(frames_per_batch // minibatch_size):\n",
    "                subdata = replay_buffer.sample()\n",
    "\n",
    "                loss_vals = loss_module(subdata)\n",
    "\n",
    "                loss_value = (\n",
    "                    loss_vals[\"loss_actor\"]\n",
    "                    + loss_vals[\"loss_qvalue\"]\n",
    "                    + loss_vals[\"loss_alpha\"]\n",
    "                )\n",
    "\n",
    "                optim.zero_grad()\n",
    "                loss_value.backward()\n",
    "                optim.step()\n",
    "\n",
    "                # update qnet_target params\n",
    "                target_net_updater.step()\n",
    "\n",
    "        # update weights of the inference policy\n",
    "        collector.update_policy_weights_()\n",
    "\n",
    "        # Logging\n",
    "        done = tensordict_data.get((\"next\", \"done\"))\n",
    "        episode_reward_mean = (\n",
    "            tensordict_data.get((\"next\", \"reward\"))[done].mean().item()\n",
    "        )\n",
    "        episode_reward_mean_list.append(episode_reward_mean)\n",
    "        pbar.set_description(f\"episode_reward_mean = {round(episode_reward_mean, 4)}\", refresh=False)\n",
    "        pbar.update()\n",
    "\n",
    "    pbar.close()\n",
    "    collector.shutdown()\n",
    "    replay_buffer.empty()\n",
    "    \n",
    "    return episode_reward_mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: TensorDictModule failed with operation\n    Sequential(\n      (0): MLP(\n        (0): Linear(in_features=23, out_features=256, bias=True)\n        (1): LeakyReLU(negative_slope=0.01)\n        (2): Linear(in_features=256, out_features=64, bias=True)\n        (3): LeakyReLU(negative_slope=0.01)\n        (4): Linear(in_features=64, out_features=32, bias=True)\n        (5): LeakyReLU(negative_slope=0.01)\n        (6): Linear(in_features=32, out_features=14, bias=True)\n      )\n      (1): NormalParamExtractor()\n    )\n    in_keys=['observation']\n    out_keys=['loc', 'scale'].",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m policy \u001b[38;5;241m=\u001b[39m make_policy_module(env, layers_config, device)\n\u001b[1;32m      2\u001b[0m Qval \u001b[38;5;241m=\u001b[39m make_Qval_module(env, layers_config, device)\n\u001b[0;32m----> 3\u001b[0m collector \u001b[38;5;241m=\u001b[39m \u001b[43mmake_collector\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_per_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_random_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps_per_traj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m replay_buffer \u001b[38;5;241m=\u001b[39m make_replay_buffer(frames_per_batch, minibatch_size, device)\n\u001b[1;32m      5\u001b[0m loss_module, target_net_updater, optim \u001b[38;5;241m=\u001b[39m make_loss_module(env, policy, Qval, value_loss, gamma, polyak, lr)\n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mmake_collector\u001b[0;34m(env, policy, device, storing_device, frames_per_batch, init_random_frames, total_frames, max_steps_per_traj)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_collector\u001b[39m(env, policy, device, storing_device, frames_per_batch, init_random_frames, total_frames, max_steps_per_traj\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSyncDataCollector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstoring_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstoring_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframes_per_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframes_per_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_random_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_random_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_frames_per_traj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps_per_traj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torchrl/collectors/collectors.py:791\u001b[0m, in \u001b[0;36mSyncDataCollector.__init__\u001b[0;34m(self, create_env_fn, policy, frames_per_batch, total_frames, device, storing_device, policy_device, env_device, create_env_kwargs, max_frames_per_traj, init_random_frames, reset_at_each_iter, postproc, split_trajs, exploration_type, exploration_mode, return_same_td, reset_when_done, interruptor)\u001b[0m\n\u001b[1;32m    787\u001b[0m policy_input_copy \u001b[38;5;241m=\u001b[39m policy_input\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    788\u001b[0m policy_input_clone \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    789\u001b[0m     policy_input\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    790\u001b[0m )  \u001b[38;5;66;03m# to test if values have changed in-place\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m policy_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;66;03m# check that we don't have exclusive keys, because they don't appear in keys\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_exclusive\u001b[39m(val):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    591\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/common.py:291\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/_contextlib.py:126\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/utils.py:261\u001b[0m, in \u001b[0;36mset_skip_existing.__call__.<locals>.wrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    256\u001b[0m     skip_existing()\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mkeys(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m out_keys)\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m out_keys \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m in_keys)\n\u001b[1;32m    259\u001b[0m ):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensordict\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/probabilistic.py:554\u001b[0m, in \u001b[0;36mProbabilisticTensorDictSequential.forward\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m(auto_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;129m@set_skip_existing\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    553\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorDictBase:\n\u001b[0;32m--> 554\u001b[0m     tensordict_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dist_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](tensordict_out, _requires_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_sample)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/probabilistic.py:520\u001b[0m, in \u001b[0;36mProbabilisticTensorDictSequential.get_dist_params\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdefault_interaction_type\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_interaction_type(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    591\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/common.py:291\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/_contextlib.py:126\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/utils.py:261\u001b[0m, in \u001b[0;36mset_skip_existing.__call__.<locals>.wrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    256\u001b[0m     skip_existing()\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mkeys(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m out_keys)\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m out_keys \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m in_keys)\n\u001b[1;32m    259\u001b[0m ):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensordict\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/sequence.py:428\u001b[0m, in \u001b[0;36mTensorDictSequential.forward\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs):\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule:\n\u001b[0;32m--> 428\u001b[0m         tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorDictSequential does not support keyword arguments other than \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensordict_out\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or in_keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m     )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/sequence.py:409\u001b[0m, in \u001b[0;36mTensorDictSequential._run_module\u001b[0;34m(self, module, tensordict, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_module\u001b[39m(\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    402\u001b[0m     module: TensorDictModule,\n\u001b[1;32m    403\u001b[0m     tensordict: TensorDictBase,\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    405\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_tolerant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    407\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mkeys(include_nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39min_keys\n\u001b[1;32m    408\u001b[0m     ):\n\u001b[0;32m--> 409\u001b[0m         tensordict \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_tolerant \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensordict, LazyStackedTensorDict):\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sub_td \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mtensordicts:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    591\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/common.py:291\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/_contextlib.py:126\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/utils.py:261\u001b[0m, in \u001b[0;36mset_skip_existing.__call__.<locals>.wrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    256\u001b[0m     skip_existing()\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mkeys(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m out_keys)\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m out_keys \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m in_keys)\n\u001b[1;32m    259\u001b[0m ):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensordict\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/common.py:1217\u001b[0m, in \u001b[0;36mTensorDictModule.forward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1215\u001b[0m in_keys \u001b[38;5;241m=\u001b[39m indent(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1216\u001b[0m out_keys \u001b[38;5;241m=\u001b[39m indent(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorDictModule failed with operation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1219\u001b[0m )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/common.py:1191\u001b[0m, in \u001b[0;36mTensorDictModule.forward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1186\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome tensors that are necessary for the module call may \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1187\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot have not been found in the input tensordict: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1188\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe following inputs are None: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnone_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1189\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mdict\u001b[39m, TensorDictBase)):\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/common.py:1177\u001b[0m, in \u001b[0;36mTensorDictModule.forward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(tensordict\u001b[38;5;241m.\u001b[39mget(in_key, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m in_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys)\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1177\u001b[0m     tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/common.py:1134\u001b[0m, in \u001b[0;36mTensorDictModule._call_module\u001b[0;34m(self, tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_module\u001b[39m(\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m, tensors: Sequence[Tensor], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   1133\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor \u001b[38;5;241m|\u001b[39m Sequence[Tensor]:\n\u001b[0;32m-> 1134\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    591\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    591\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torchrl/modules/models/models.py:267\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    265\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;241m*\u001b[39minputs], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),)\n\u001b[0;32m--> 267\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features, Number):\n\u001b[1;32m    269\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mout\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensordict/nn/functional_modules.py:589\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    591\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "policy = make_policy_module(env, layers_config, device)\n",
    "Qval = make_Qval_module(env, layers_config, device)\n",
    "collector = make_collector(env, policy, device, device, frames_per_batch, init_random_frames=0, total_frames=total_frames, max_steps_per_traj=max_steps)\n",
    "replay_buffer = make_replay_buffer(frames_per_batch, minibatch_size, device)\n",
    "loss_module, target_net_updater, optim = make_loss_module(env, policy, Qval, value_loss, gamma, polyak, lr)\n",
    "episode_reward_mean_list = training_loop(env, loss_module, target_net_updater, optim, collector, replay_buffer, n_iters, num_epochs, frames_per_batch, minibatch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episode_reward_mean_list)\n",
    "plt.xlabel(\"Training iterations\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Episode reward mean\")\n",
    "plt.savefig('Episode reward mean', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
